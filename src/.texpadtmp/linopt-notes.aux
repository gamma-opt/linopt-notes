\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{7}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter_1}{{1}{7}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}What is optimisation?}{7}{section.1.1}\protected@file@percent }
\newlabel{p1c1:eq:opt_prob}{{1.1}{7}{What is optimisation?}{equation.1.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Mathematical programming and optimisation}{7}{subsection.1.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Types of mathematical optimisation models}{8}{subsection.1.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Linear programming applications}{9}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Resource allocation}{9}{subsection.1.2.1}\protected@file@percent }
\newlabel{section_121}{{1.2.1}{9}{Resource allocation}{subsection.1.2.1}{}}
\citation{taha2003operations}
\newlabel{p1c1:eq:LP_objective}{{1.2}{10}{Resource allocation}{equation.1.2.2}{}}
\newlabel{p1c1:eq:LP_constraint}{{1.3}{10}{Resource allocation}{equation.1.2.3}{}}
\newlabel{p1c1:eq:LP_domain}{{1.4}{10}{Resource allocation}{equation.1.2.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{Illustrative example: the paint factory problem \cite  {taha2003operations}}{10}{section*.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces Paint factory problem data}}{10}{table.caption.3}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{p1c1:tab:paint_factory_problem_data}{{1.1}{10}{Paint factory problem data}{table.caption.3}{}}
\newlabel{p1c1:eq:constM1}{{1.5}{10}{Illustrative example: the paint factory problem \cite {taha2003operations}}{equation.1.2.5}{}}
\newlabel{p1c1:eq:constM2}{{1.6}{10}{Illustrative example: the paint factory problem \cite {taha2003operations}}{equation.1.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Transportation problem}{11}{subsection.1.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Schematic illustration of a network with two source nodes and three demand nodes}}{11}{figure.caption.4}\protected@file@percent }
\newlabel{p1c1:fig1:transport_network}{{1.1}{11}{Schematic illustration of a network with two source nodes and three demand nodes}{figure.caption.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1.2}{\ignorespaces Problem data: unit transportation costs, demands and capacities}}{11}{table.caption.5}\protected@file@percent }
\newlabel{p1c1:tab:transport_problem_data}{{1.2}{11}{Problem data: unit transportation costs, demands and capacities}{table.caption.5}{}}
\newlabel{p1c1:eq:transportation_constraint_supply}{{1.11}{12}{Transportation problem}{equation.1.2.11}{}}
\newlabel{p1c1:eq:transportation_constraint_demand}{{1.12}{12}{Transportation problem}{equation.1.2.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Production planning (lot-sizing)}{13}{subsection.1.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces A schematic representation of the lot-sizing problem. Each node represents the material balance at each time period $t$.}}{13}{figure.caption.6}\protected@file@percent }
\newlabel{p1c1:fig:lot-sizing_diagram}{{1.2}{13}{A schematic representation of the lot-sizing problem. Each node represents the material balance at each time period $t$}{figure.caption.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}The geometry of LPs - graphical method}{14}{section.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}The graphical method}{14}{subsection.1.3.1}\protected@file@percent }
\newlabel{p1c1:fig:fig3a}{{1.3a}{14}{\relax }{figure.caption.7}{}}
\newlabel{sub@p1c1:fig:fig3a}{{a}{14}{\relax }{figure.caption.7}{}}
\newlabel{p1c1:fig:fig3b}{{1.3b}{14}{\relax }{figure.caption.7}{}}
\newlabel{sub@p1c1:fig:fig3b}{{b}{14}{\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces The feasible region of the paint factory problem (in Figure \ref {p1c1:fig:fig3b}), represented as the intersection of the four closed-half spaces formed by each of the constraints (as shown in Figure \ref {p1c1:fig:fig3a}). Notice how the feasible region is a polyhedral set in $\mathbb  {R}^2$, as there are two decision variables ($x_1$ and $x_2$).}}{14}{figure.caption.7}\protected@file@percent }
\newlabel{p1c1:fig:feasible_region_plot}{{1.3}{14}{The feasible region of the paint factory problem (in Figure \ref {p1c1:fig:fig3b}), represented as the intersection of the four closed-half spaces formed by each of the constraints (as shown in Figure \ref {p1c1:fig:fig3a}). Notice how the feasible region is a polyhedral set in $\reals ^2$, as there are two decision variables ($x_1$ and $x_2$)}{figure.caption.7}{}}
\newlabel{p1c1:fig:level_curves_a}{{1.4a}{15}{\relax }{figure.caption.8}{}}
\newlabel{sub@p1c1:fig:level_curves_a}{{a}{15}{\relax }{figure.caption.8}{}}
\newlabel{p1c1:fig:level_curves_b}{{1.4b}{15}{\relax }{figure.caption.8}{}}
\newlabel{sub@p1c1:fig:level_curves_b}{{b}{15}{\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Graphical representation of some of the level curves of the objective function $z = 5x_1 + 4x_2$. Notice that the constant gradient vector $\nabla z = (5,4)^\top $ points to the direction in which the level curves increase in value. The optimal point is represented by $x^*=(3, 1.5)^\top $ with the furthermost level curve being that associated with the value $z^* = 21$}}{15}{figure.caption.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}Geometrical properties of LPs}{16}{subsection.1.3.2}\protected@file@percent }
\citation{kwon2019julia}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Exercises}{17}{section.1.4}\protected@file@percent }
\citation{birge2011introduction}
\@writefile{lot}{\contentsline {table}{\numberline {1.3}{\ignorespaces Problem data: unit transportation costs, demands and capacities}}{18}{table.caption.12}\protected@file@percent }
\citation{williams2013model}
\newlabel{p1c1:tab:ex1-4_suplly_demand}{{1.4a}{19}{Supply availability and demand per oil type [in L]}{table.caption.14}{}}
\newlabel{sub@p1c1:tab:ex1-4_suplly_demand}{{a}{19}{Supply availability and demand per oil type [in L]}{table.caption.14}{}}
\newlabel{p1c1:tab:ex1-4_arcs}{{1.4b}{19}{Arcs costs per oil type [in \euro \ per L] and arc capacities [in L]}{table.caption.14}{}}
\newlabel{sub@p1c1:tab:ex1-4_arcs}{{b}{19}{Arcs costs per oil type [in \euro \ per L] and arc capacities [in L]}{table.caption.14}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1.4}{\ignorespaces Supply chain data}}{19}{table.caption.14}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.5}{\ignorespaces Product yields}}{20}{table.caption.17}\protected@file@percent }
\newlabel{p1c1:tab:ex1-5_prod_yield}{{1.5}{20}{Product yields}{table.caption.17}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1.6}{\ignorespaces Maximum demand}}{20}{table.caption.18}\protected@file@percent }
\newlabel{p1c1:tab:ex1-5_max_demand}{{1.6}{20}{Maximum demand}{table.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Two sets of data points defined by two features, separated by a line $ax=b$}}{21}{figure.caption.20}\protected@file@percent }
\newlabel{p1c1:fig:fig_e16}{{1.5}{21}{Two sets of data points defined by two features, separated by a line $ax=b$}{figure.caption.20}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Basics of Linear Algebra}{23}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter_2}{{2}{23}{Basics of Linear Algebra}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Basics of linear problems}{23}{section.2.1}\protected@file@percent }
\newlabel{p1c2:eq:feasible_region_inequality}{{2.1}{23}{Basics of linear problems}{equation.2.1.1}{}}
\newlabel{p1c2:def:matrix_inversion}{{2.1}{23}{Matrix inversion}{theorem.2.1}{}}
\newlabel{p1c2:def:linear_independence}{{2.2}{23}{Linearly independent vectors}{theorem.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Linearly independent (top) and dependent (bottom) vectors in $\mathbb  {R}^2$. Notice how, in the bottom picture, any of the vectors can be obtained by appropriately scaling and adding the other two}}{24}{figure.caption.21}\protected@file@percent }
\newlabel{p1c2:fig:linear_independence}{{2.1}{24}{Linearly independent (top) and dependent (bottom) vectors in $\reals ^2$. Notice how, in the bottom picture, any of the vectors can be obtained by appropriately scaling and adding the other two}{figure.caption.21}{}}
\newlabel{p1c2:thm:fundamental_linear_algebra}{{2.3}{24}{Inverses, linear independence, and solving $Ax = b$}{theorem.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Subspaces and bases}{24}{subsection.2.1.1}\protected@file@percent }
\newlabel{p1c2:thm:LI_and_bases}{{2.4}{25}{Forming bases from linearly independent vectors}{theorem.2.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces One- (left) and two-dimensional subspaces (right) in $\mathbb  {R}^3$.}}{26}{figure.caption.22}\protected@file@percent }
\newlabel{p1c2:fig:proper_subpaces}{{2.2}{26}{One- (left) and two-dimensional subspaces (right) in $\reals ^3$}{figure.caption.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Affine subspaces}{26}{subsection.2.1.2}\protected@file@percent }
\newlabel{p1c2:eq:equality_constraint_feasible_set}{{2.2}{26}{Affine subspaces}{equation.2.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces The affine subspace $S$ generated by $x_0$ and $\mathop {\bf  null}(a)$. Notice that all vectors in $S$, exemplified by $x_1$ and $x_2$ are perpendicular (i.e., have null dot product) to $a$}}{27}{figure.caption.23}\protected@file@percent }
\newlabel{p1c2:fig:nill_space_a}{{2.3}{27}{The affine subspace $S$ generated by $x_0$ and $\nulls (a)$. Notice that all vectors in $S$, exemplified by $x_1$ and $x_2$ are perpendicular (i.e., have null dot product) to $a$}{figure.caption.23}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Convex polyhedral set}{27}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Hyperplanes, half-spaces and polyhedral sets}{27}{subsection.2.2.1}\protected@file@percent }
\newlabel{p1c2:def:polyhedral_sets}{{2.5}{27}{Polyhedral set}{theorem.2.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces A hyperplane and its respective halfspaces (left) and the polyhedral set $\left \{ x\in \mathbb  {R}^{2} : a_i^x \geq b_i, i =1,\dots  , 5 \right \}$ (right).}}{28}{figure.caption.24}\protected@file@percent }
\newlabel{p1c2:fig:hyperplanes_and_polyhedral_set}{{2.4}{28}{A hyperplane and its respective halfspaces (left) and the polyhedral set $\braces {x\in \reals ^{2} : a_i^x \geq b_i, i =1,\dots , 5}$ (right)}{figure.caption.24}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Convexity of polyhedral sets}{28}{subsection.2.2.2}\protected@file@percent }
\newlabel{p1c2:def:convex_set}{{2.6}{28}{Convex set}{theorem.2.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Two convex sets (left and middle) and one nonconvex set (right)}}{29}{figure.caption.25}\protected@file@percent }
\newlabel{p1c2:fig:convex_sets}{{2.5}{29}{Two convex sets (left and middle) and one nonconvex set (right)}{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces The convex hull of two points is the line segment connecting them (left); The convex hull of three (centre) and six (right) points in $\mathbb  {R}^2$}}{29}{figure.caption.26}\protected@file@percent }
\newlabel{p1c2:fig:convex_hulls}{{2.6}{29}{The convex hull of two points is the line segment connecting them (left); The convex hull of three (centre) and six (right) points in $\reals ^2$}{figure.caption.26}{}}
\newlabel{p1c2:def:convex_combination_hull}{{2.7}{29}{Convex combinations and convex hulls}{theorem.2.7}{}}
\newlabel{p1c2:thm:convexity}{{2.8}{29}{Convexity of polyhedral sets}{theorem.2.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Illustration of statement 1 (left), 2 (centre), and 3 and 4 (right)}}{30}{figure.caption.27}\protected@file@percent }
\newlabel{p1c2:fig:convexity_theorem_examples}{{2.7}{30}{Illustration of statement 1 (left), 2 (centre), and 3 and 4 (right)}{figure.caption.27}{}}
\newlabel{p1c2:eq:induction}{{2.4}{30}{Convexity of polyhedral sets}{equation.2.2.4}{}}
\newlabel{p1c2:thm:convexity_and_optimality}{{2.9}{30}{Global optimality for convex problems}{theorem.2.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Extreme points, vertices, and basic feasible solutions}{31}{section.2.3}\protected@file@percent }
\newlabel{p1c2:def:vertex}{{2.10}{31}{Vertex}{theorem.2.10}{}}
\newlabel{p1c2:def:extreme_point}{{2.11}{31}{Extreme points}{theorem.2.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Representation of a vertex (left) and a extreme point (right)}}{32}{figure.caption.28}\protected@file@percent }
\newlabel{p1c2:fig:vertex_and_extreme_point}{{2.8}{32}{Representation of a vertex (left) and a extreme point (right)}{figure.caption.28}{}}
\newlabel{p1c2:fig:active_constraint}{{2.12}{32}{Active (or binding) constraints}{theorem.2.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Representation of $P$ in $\mathbb  {R}^3$.}}{32}{figure.caption.29}\protected@file@percent }
\newlabel{p1c2:fig:active_constraints}{{2.9}{32}{Representation of $P$ in $\reals ^3$}{figure.caption.29}{}}
\newlabel{p1c2:thm:active_const}{{2.13}{32}{Properties of active constraints}{theorem.2.13}{}}
\newlabel{p1c2:def:basic_feasible_solution}{{2.14}{33}{Basic feasible solution (BFS)}{theorem.2.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Points $A$ to $F$ are basic solutions; $B$,$C$,$D$, and $E$ are BFS.}}{33}{figure.caption.30}\protected@file@percent }
\newlabel{p1c2:fig:BFS}{{2.10}{33}{Points $A$ to $F$ are basic solutions; $B$,$C$,$D$, and $E$ are BFS}{figure.caption.30}{}}
\newlabel{p1c2:thm:BFS_vertex_extreme_point}{{2.15}{34}{BFS, extreme points and vertices}{theorem.2.15}{}}
\citation{bertsimas1997introduction}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Exercises}{35}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Basis, Extreme Points and Optimality in Linear Programming}{39}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter_3}{{3}{39}{Basis, Extreme Points and Optimality in Linear Programming}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Polyhedral sets in standard form}{39}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}The standard form of linear programming problems}{39}{subsection.3.1.1}\protected@file@percent }
\newlabel{p1c3:thm:LI_and_bases}{{3.1}{40}{Linear independence and basic solutions}{theorem.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Forming bases for standard-form linear programming problems}{41}{subsection.3.1.2}\protected@file@percent }
\newlabel{p1c3:eq:example_P}{{3.1}{42}{Forming bases for standard-form linear programming problems}{equation.3.1.1}{}}
\newlabel{p1c3:eq:example_P}{{3.2}{42}{Forming bases for standard-form linear programming problems}{equation.3.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Adjacent basic solutions}{42}{subsection.3.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}Redundancy and degeneracy}{43}{subsection.3.1.4}\protected@file@percent }
\newlabel{p1c3:thm:red_const}{{3.3}{43}{Redundant constraints}{theorem.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces $A$ is a degenerate basic solution, $B$ and $C$ are degenerate BFS, and $D$ is a BFS.}}{44}{figure.caption.38}\protected@file@percent }
\newlabel{p1c3:fig:figure1}{{3.1}{44}{$A$ is a degenerate basic solution, $B$ and $C$ are degenerate BFS, and $D$ is a BFS}{figure.caption.38}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Optimality of extreme points}{44}{section.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces $(0,0,1)$ is degenerate if you add the constraint $x_2 \ge 0$.}}{45}{figure.caption.39}\protected@file@percent }
\newlabel{p1c3:fig:redundancy_and_degeneration}{{3.2}{45}{$(0,0,1)$ is degenerate if you add the constraint $x_2 \ge 0$}{figure.caption.39}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}The existence of extreme points}{45}{subsection.3.2.1}\protected@file@percent }
\newlabel{p1c3:def:line_containing}{{3.4}{45}{Existence of extreme points}{theorem.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces $P$ contains a line (left) and $Q$ does not contain a line (right)}}{45}{figure.caption.40}\protected@file@percent }
\newlabel{p1c3:fig:line_containing}{{3.3}{45}{$P$ contains a line (left) and $Q$ does not contain a line (right)}{figure.caption.40}{}}
\newlabel{p1c3:thm:exist_extreme_point}{{3.5}{45}{Existence of extreme points}{theorem.3.5}{}}
\newlabel{p1c3:thm:opt_extreme}{{3.6}{46}{Optimality of extreme points}{theorem.3.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Finding optimal solutions}{47}{subsection.3.2.2}\protected@file@percent }
\newlabel{p1c3:def:feasible_direction}{{3.7}{47}{Feasible directions}{theorem.3.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Feasible directions at different points of $P$}}{48}{figure.caption.41}\protected@file@percent }
\newlabel{p1c3:fig:feasible_directions}{{3.4}{48}{Feasible directions at different points of $P$}{figure.caption.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Example: $n = 5$ and $n-m = 2$. At $A$, $x_1 = x_3 = 0$ and $x_2, x_4, x_5 \geq 0$. Increasing $x_1$ while keeping $x_3$ zero leads to $B$. At $B$, suppose $I_N = \left \{ 3,5 \right \}$; by increasing $x_3$ while keeping $x_5$ zero would leads to $C$.}}{49}{figure.caption.42}\protected@file@percent }
\newlabel{p1c3:fig:adjacent_vertices}{{3.5}{49}{Example: $n = 5$ and $n-m = 2$. At $A$, $x_1 = x_3 = 0$ and $x_2, x_4, x_5 \geq 0$. Increasing $x_1$ while keeping $x_3$ zero leads to $B$. At $B$, suppose $I_N = \braces {3,5}$; by increasing $x_3$ while keeping $x_5$ zero would leads to $C$}{figure.caption.42}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Moving towards improved solutions}{49}{subsection.3.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Optimality conditions}{51}{subsection.3.2.4}\protected@file@percent }
\newlabel{p1c3:thm:opt_conditions}{{3.9}{51}{Optimality conditions}{theorem.3.9}{}}
\newlabel{p1c3:eq:red_cost_opt_cond}{{3.3}{51}{Optimality conditions}{equation.3.2.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Exercises}{52}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {4}The simplex method}{55}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter_4}{{4}{55}{The simplex method}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Developing the simplex method}{55}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Calculating step sizes}{55}{subsection.4.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Moving between adjacent bases}{56}{subsection.4.1.2}\protected@file@percent }
\newlabel{p1c4:eq:selected_basic_variable}{{4.1}{56}{Moving between adjacent bases}{equation.4.1.1}{}}
\newlabel{p1c4:thm:adjacent_basis}{{4.1}{57}{Adjacent bases}{theorem.4.1}{}}
\newlabel{p1c4:thm:convergece_simplex}{{4.2}{57}{Convergence of the simplex method}{theorem.4.2}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Simplex method}}{58}{algorithm.caption.48}\protected@file@percent }
\newlabel{p1c4:alg:simplex}{{1}{58}{Simplex method}{algorithm.caption.48}{}}
\newlabel{p1c4:alg:opt_condition}{{2}{58}{Simplex method}{algorithm.caption.48}{}}
\newlabel{p1c4:alg:unb_condition}{{4}{58}{Simplex method}{algorithm.caption.48}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}A remark on degeneracy}{58}{subsection.4.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces  $I_N = \left \{ 4,5 \right \}$ for $x$; $f$ ($x_5 > 0$) and $g$ ($x_4 >0$) are basic directions. Making $I_N = \left \{ 2,5 \right \}$ lead to new basic directions $h$ ($x_4 > 0$) and $-g$ ($x_2 > 0$).}}{59}{figure.caption.49}\protected@file@percent }
\newlabel{p1c4:fig:degenerate_basis}{{4.1}{59}{$I_N = \braces {4,5}$ for $x$; $f$ ($x_5 > 0$) and $g$ ($x_4 >0$) are basic directions. Making $I_N = \braces {2,5}$ lead to new basic directions $h$ ($x_4 > 0$) and $-g$ ($x_2 > 0$)}{figure.caption.49}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Implementing the simplex method}{59}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Pivot or variable selection}{59}{subsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}The revised simplex method}{60}{subsection.4.2.2}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Revised simplex method}}{62}{algorithm.caption.50}\protected@file@percent }
\newlabel{p1c4:alg:revised_ximplex_method}{{2}{62}{Revised simplex method}{algorithm.caption.50}{}}
\newlabel{p1c4:alg:opt_condition_rev}{{3}{62}{Revised simplex method}{algorithm.caption.50}{}}
\newlabel{p1c4:alg:unb_condition_rev}{{5}{62}{Revised simplex method}{algorithm.caption.50}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Tableau representation}{62}{subsection.4.2.3}\protected@file@percent }
\newlabel{p1c1:eq:constM1}{{4.2}{64}{Tableau representation}{equation.4.2.2}{}}
\newlabel{p1c1:eq:constM2}{{4.3}{64}{Tableau representation}{equation.4.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}Generating initial feasible solutions (two-phase simplex)}{64}{subsection.4.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Column geometry of the simplex method}{66}{section.4.3}\protected@file@percent }
\newlabel{p1c4:def:simplex}{{4.4}{67}{$k$-dimensional simplex}{theorem.4.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces A solution $x$ is a convex combinations of $(A_i,c_i)$ such that $Ax= b$.}}{67}{figure.caption.51}\protected@file@percent }
\newlabel{p1c4:fig:column_geometry}{{4.2}{67}{A solution $x$ is a convex combinations of $(A_i,c_i)$ such that $Ax= b$}{figure.caption.51}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces A solution $x$ is a convex combinations of $(A_i,c_i)$ such that $Ax= b$.}}{68}{figure.caption.52}\protected@file@percent }
\newlabel{p1c4:fig:column_geometry_3d}{{4.3}{68}{A solution $x$ is a convex combinations of $(A_i,c_i)$ such that $Ax= b$}{figure.caption.52}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Pivots from initial basis $[A_3, A_6]$ to $[A_3, A_5]$ and to the optimal basis $[A_8, A_5]$}}{68}{figure.caption.53}\protected@file@percent }
\newlabel{p1c4:fig:column_geometry_projection}{{4.4}{68}{Pivots from initial basis $[A_3, A_6]$ to $[A_3, A_5]$ and to the optimal basis $[A_8, A_5]$}{figure.caption.53}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Exercises}{70}{section.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Linear Programming Duality - Part I}{73}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter_5}{{5}{73}{Linear Programming Duality - Part I}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Formulating duals}{73}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Motivation}{73}{subsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}General form of duals}{74}{subsection.5.1.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Primal-dual conversion table}}{76}{table.caption.58}\protected@file@percent }
\newlabel{p1c5:tab:primal-dual_conversion}{{5.1}{76}{Primal-dual conversion table}{table.caption.58}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Duality theory}{77}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Weak duality}{77}{subsection.5.2.1}\protected@file@percent }
\newlabel{p1c5:thm:weak_duality}{{5.1}{77}{Weak duality}{theorem.5.1}{}}
\newlabel{p1c5:cor:weak_duality}{{5.2}{77}{Consequences of weak duality}{theorem.5.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Strong duality}{78}{subsection.5.2.2}\protected@file@percent }
\newlabel{p1c5:thm:strong_duality}{{5.3}{78}{Strong duality}{theorem.5.3}{}}
\newlabel{p1c5:eq:primal-dual}{{5.1}{78}{Strong duality}{equation.5.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Geometric interpretation of duality}{79}{section.5.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces A geometric representation of duality for linear programming problems}}{79}{figure.caption.59}\protected@file@percent }
\newlabel{p1c5:fig:duality_geometry}{{5.1}{79}{A geometric representation of duality for linear programming problems}{figure.caption.59}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Complementary slackness}{79}{subsection.5.3.1}\protected@file@percent }
\newlabel{p1c2:thm:complemetarity_slackness}{{5.4}{80}{Complementary slackness}{theorem.5.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Dual feasibility and optimality}{80}{subsection.5.3.2}\protected@file@percent }
\newlabel{p1c5:eq:primal_feas}{{5.2}{80}{Dual feasibility and optimality}{equation.5.3.2}{}}
\newlabel{p1c5:eq:cc}{{5.3}{80}{Dual feasibility and optimality}{equation.5.3.3}{}}
\newlabel{p1c5:eq:dual_feasI}{{5.4}{80}{Dual feasibility and optimality}{equation.5.3.4}{}}
\newlabel{p1c5:eq:dual_feasII}{{5.5}{80}{Dual feasibility and optimality}{equation.5.3.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces $A$ is both primal and dual infeasible; $B$ is primal feasible and dual infeasible; $C$ is primal and dual feasible; $D$ is degenerate.}}{81}{figure.caption.60}\protected@file@percent }
\newlabel{p1c5:fig:dual_feasibility}{{5.2}{81}{$A$ is both primal and dual infeasible; $B$ is primal feasible and dual infeasible; $C$ is primal and dual feasible; $D$ is degenerate}{figure.caption.60}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}The dual simplex method}{81}{section.5.4}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Dual simplex method}}{82}{algorithm.caption.61}\protected@file@percent }
\newlabel{p1c5:alg:dual_simplex}{{3}{82}{Dual simplex method}{algorithm.caption.61}{}}
\newlabel{alg:opt_condition}{{2}{82}{Dual simplex method}{algorithm.caption.61}{}}
\newlabel{alg:unb_condition}{{4}{82}{Dual simplex method}{algorithm.caption.61}{}}
\newlabel{p1c5:fig:ex1_P}{{5.3a}{84}{The primal-variable space}{figure.caption.62}{}}
\newlabel{sub@p1c5:fig:ex1_P}{{a}{84}{The primal-variable space}{figure.caption.62}{}}
\newlabel{p1c5:fig:ex1_D}{{5.3b}{84}{The dual-variable space}{figure.caption.62}{}}
\newlabel{sub@p1c5:fig:ex1_D}{{b}{84}{The dual-variable space}{figure.caption.62}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces The progress of the dual simplex method in the primal and dual space.}}{84}{figure.caption.62}\protected@file@percent }
\newlabel{p1c5:fig:ex1}{{5.3}{84}{The progress of the dual simplex method in the primal and dual space}{figure.caption.62}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Exercises}{85}{section.5.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Problem data: unit transportation costs, demands and capacities}}{85}{table.caption.64}\protected@file@percent }
\newlabel{p1c5:tab:E51_transport_problem_data}{{5.2}{85}{Problem data: unit transportation costs, demands and capacities}{table.caption.64}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Linear Programming Duality - Part II}{89}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter_6}{{6}{89}{Linear Programming Duality - Part II}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Sensitivity analysis}{89}{section.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.1}Adding a new variable}{90}{subsection.6.1.1}\protected@file@percent }
\newlabel{section_611}{{6.1.1}{90}{Adding a new variable}{subsection.6.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.2}Adding a new constraint}{91}{subsection.6.1.2}\protected@file@percent }
\newlabel{section_612}{{6.1.2}{91}{Adding a new constraint}{subsection.6.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.3}Changing input data}{92}{subsection.6.1.3}\protected@file@percent }
\newlabel{section_613}{{6.1.3}{92}{Changing input data}{subsection.6.1.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{Optimal dual variables as marginal costs}{93}{section*.69}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Changes in the vector $b$}{94}{section*.70}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Changes in the vector $c$}{94}{section*.71}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Cones and extreme rays}{96}{section.6.2}\protected@file@percent }
\newlabel{p1c6:def:cone}{{6.1}{96}{Cones}{theorem.6.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces A polyhedral cone in $\mathbb  {R}^3$ formed by 3 half-space}}{96}{figure.caption.72}\protected@file@percent }
\newlabel{p1c6:fig:poly_cone}{{6.1}{96}{A polyhedral cone in $\reals ^3$ formed by 3 half-space}{figure.caption.72}{}}
\newlabel{p1c6:cor:polyhedral_cones}{{6.2}{96}{}{theorem.6.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}Recession cones and extreme rays}{97}{subsection.6.2.1}\protected@file@percent }
\newlabel{section_621}{{6.2.1}{97}{Recession cones and extreme rays}{subsection.6.2.1}{}}
\newlabel{c1_p6:def:recession_cone}{{6.3}{97}{Recession cone}{theorem.6.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Representation of the recession cone of a polyhedral set}}{97}{figure.caption.73}\protected@file@percent }
\newlabel{p1c6:fig:recession_cone}{{6.2}{97}{Representation of the recession cone of a polyhedral set}{figure.caption.73}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}Unbounded problems}{97}{subsection.6.2.2}\protected@file@percent }
\newlabel{p1c6:def:extreme_ray}{{6.4}{97}{Extreme ray}{theorem.6.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces A polyhedral cone formed by the intersection of three half-spaces (the normal vector $a_3$ is perpendicular to the plane of the picture and cannot be seen). Directions $d_1$, $d_2$, and $d_3$ represent extreme rays.}}{98}{figure.caption.74}\protected@file@percent }
\newlabel{p1c6:fig:extreme_rays}{{6.3}{98}{A polyhedral cone formed by the intersection of three half-spaces (the normal vector $a_3$ is perpendicular to the plane of the picture and cannot be seen). Directions $d_1$, $d_2$, and $d_3$ represent extreme rays}{figure.caption.74}{}}
\newlabel{p1c6:thm:unb_cones}{{6.5}{98}{Unboundedness in polyhedral cones}{theorem.6.5}{}}
\newlabel{p1c6:thm:unb_polyhedra}{{6.6}{98}{Unboundedness in polyhedral sets}{theorem.6.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.3}Farkas' lemma}{99}{subsection.6.2.3}\protected@file@percent }
\newlabel{p1c6:thm:farkas}{{6.7}{99}{Farkas' lemma}{theorem.6.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces Since $b \not \in X$, $p^\top x=0$ separates them}}{100}{figure.caption.75}\protected@file@percent }
\newlabel{p1c6:fig:farkas}{{6.4}{100}{Since $b \not \in X$, $p^\top x=0$ separates them}{figure.caption.75}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Exercises}{101}{section.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Barrier Method for Linear Programming}{103}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter_7}{{7}{103}{Barrier Method for Linear Programming}{chapter.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Barrier methods}{103}{section.7.1}\protected@file@percent }
\newlabel{section_71}{{7.1}{103}{Barrier methods}{section.7.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Newton's method with equality constraints}{103}{section.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Interior point methods linear programming problems}{105}{section.7.3}\protected@file@percent }
\newlabel{p1c7:eq:optimality_conditions_primal}{{7.1}{105}{Interior point methods linear programming problems}{equation.7.3.1}{}}
\newlabel{p1c7:eq:optimality_conditions_dual}{{7.2}{105}{Interior point methods linear programming problems}{equation.7.3.2}{}}
\newlabel{p1c7:eq:optimality_conditions_cc}{{7.3}{105}{Interior point methods linear programming problems}{equation.7.3.3}{}}
\newlabel{p1c7:eq:optimality_conditions_matrix_primal}{{7.4}{106}{Interior point methods linear programming problems}{equation.7.3.4}{}}
\newlabel{p1c7:eq:optimality_conditions_matrix_dual}{{7.5}{106}{Interior point methods linear programming problems}{equation.7.3.5}{}}
\newlabel{p1c7:eq:optimality_conditions_matrix_relaxed_cc}{{7.6}{106}{Interior point methods linear programming problems}{equation.7.3.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.4}Barrier methods for linear programming problems}{107}{section.7.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces Alternative barrier functions for different values of $\mu $. The dashed line represents the indicator function $I(x)$ going to infinity when $x > 0$}}{108}{figure.caption.80}\protected@file@percent }
\newlabel{p1c7:fig:barrier_function}{{7.1}{108}{Alternative barrier functions for different values of $\mu $. The dashed line represents the indicator function $I(x)$ going to infinity when $x > 0$}{figure.caption.80}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.2}{\ignorespaces The optimal values of $P_\mu $ for different values of $\mu $. Notice the trajectory formed by the points $x^*(\mu )$ as $\mu \to 0$.}}{109}{figure.caption.81}\protected@file@percent }
\newlabel{p1c7:fig:example-barrier}{{7.2}{109}{The optimal values of $P_\mu $ for different values of $\mu $. Notice the trajectory formed by the points $x^*(\mu )$ as $\mu \to 0$}{figure.caption.81}{}}
\@writefile{toc}{\contentsline {subsubsection}{The notion of interiority}{109}{section*.82}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.5}Barrier methods for linear programming problems}{110}{section.7.5}\protected@file@percent }
\citation{gondzio2012interior}
\@writefile{toc}{\contentsline {subsubsection}{A practical implementation of the barrier method}{111}{section*.83}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.3}{\ignorespaces An illustrative representation of the central path and how the method follows it approximately}}{112}{figure.caption.84}\protected@file@percent }
\newlabel{p1c7:fig:central-path-and-neighbourhoods}{{7.3}{112}{An illustrative representation of the central path and how the method follows it approximately}{figure.caption.84}{}}
\newlabel{p1c7:eq:infeasible_perturbed_system}{{7.7}{112}{A practical implementation of the barrier method}{equation.7.5.7}{}}
\citation{gondzio2012interior}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces Barrier method for LP}}{113}{algorithm.caption.85}\protected@file@percent }
\newlabel{p1c7:alg:barrier_method}{{4}{113}{Barrier method for LP}{algorithm.caption.85}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.6}Exercises}{115}{section.7.6}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Integer Programming Models}{117}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter_8}{{8}{117}{Integer Programming Models}{chapter.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Types of integer programming problems}{117}{section.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.2}(Mixed-)integer programming applications}{118}{section.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.1}The assignment problem}{118}{subsection.8.2.1}\protected@file@percent }
\newlabel{p1c8:fig:assignment_a}{{8.1a}{118}{\relax }{figure.caption.87}{}}
\newlabel{sub@p1c8:fig:assignment_a}{{a}{118}{\relax }{figure.caption.87}{}}
\newlabel{p1c8:fig:assignment_b}{{8.1b}{118}{\relax }{figure.caption.87}{}}
\newlabel{sub@p1c8:fig:assignment_b}{{b}{118}{\relax }{figure.caption.87}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.1}{\ignorespaces An illustration of all potential assignments as a graph and an example of one possible assignment, with total cost $C_{12}$ + $C_{31}$ + $C_{24}$ + $C_{43}$}}{118}{figure.caption.87}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.2}The knapsack problem}{119}{subsection.8.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.3}The generalised assignment problem}{119}{subsection.8.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.2}{\ignorespaces An example of a bin packing with total cost $C_{11}$ + $C_{12}$ + $C_{23}$ + $C_{44}$}}{120}{figure.caption.88}\protected@file@percent }
\newlabel{p1c8:fig:bin_packing}{{8.2}{120}{An example of a bin packing with total cost $C_{11}$ + $C_{12}$ + $C_{23}$ + $C_{44}$}{figure.caption.88}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.4}The set covering problem}{120}{subsection.8.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.3}{\ignorespaces The hive map illustrating the set covering problem. Our objective is to cover all of the regions while minimising the total cost incurred by opening the centres at the blue cells}}{121}{figure.caption.89}\protected@file@percent }
\newlabel{p1c8:fig:set_covering}{{8.3}{121}{The hive map illustrating the set covering problem. Our objective is to cover all of the regions while minimising the total cost incurred by opening the centres at the blue cells}{figure.caption.89}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.5}Travelling salesperson problem}{122}{subsection.8.2.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.4}{\ignorespaces An example of a tour between the six cities}}{122}{figure.caption.90}\protected@file@percent }
\newlabel{p1c8:fig:TSP}{{8.4}{122}{An example of a tour between the six cities}{figure.caption.90}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.5}{\ignorespaces A feasible solution for the naive TSP model. Notice the two sub-tours formed}}{123}{figure.caption.91}\protected@file@percent }
\newlabel{p1c8:fig:TSP_subtours}{{8.5}{123}{A feasible solution for the naive TSP model. Notice the two sub-tours formed}{figure.caption.91}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.6}Uncapacitated facility location}{123}{subsection.8.2.6}\protected@file@percent }
\newlabel{p1c8:fig:facility_location_a}{{8.6a}{124}{\relax }{figure.caption.92}{}}
\newlabel{sub@p1c8:fig:facility_location_a}{{a}{124}{\relax }{figure.caption.92}{}}
\newlabel{p1c8:fig:facility_location_b}{{8.6b}{124}{\relax }{figure.caption.92}{}}
\newlabel{sub@p1c8:fig:facility_location_b}{{b}{124}{\relax }{figure.caption.92}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.6}{\ignorespaces An illustration of the facility location problem and one possible solution with two facilities located (right)}}{124}{figure.caption.92}\protected@file@percent }
\newlabel{p1c8:eq:big-M_UFL}{{8.3}{124}{Uncapacitated facility location}{equation.8.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.7}Uncapacitated lot-sizing}{125}{subsection.8.2.7}\protected@file@percent }
\newlabel{p1c8:eq:big_M_ULS}{{8.6}{125}{Uncapacitated lot-sizing}{equation.8.2.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.3}Good formulations}{125}{section.8.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.7}{\ignorespaces Graphical representation of the feasible region of the example}}{126}{figure.caption.93}\protected@file@percent }
\newlabel{p1c8:fig:IP_feasible_region}{{8.7}{126}{Graphical representation of the feasible region of the example}{figure.caption.93}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3.1}Comparing formulations}{126}{subsection.8.3.1}\protected@file@percent }
\newlabel{p1c8:def:formulation}{{8.1}{127}{}{theorem.8.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.8}{\ignorespaces An illustration of three alternative formulations for $X$. Notice that $P_3$ is an ideal formulation, representing the convex hull of $X$.}}{127}{figure.caption.94}\protected@file@percent }
\newlabel{p1c8:fig:alternative_formulations}{{8.8}{127}{An illustration of three alternative formulations for $X$. Notice that $P_3$ is an ideal formulation, representing the convex hull of $X$}{figure.caption.94}{}}
\newlabel{p1c8:prop:polyhedra_convex_hull}{{8.2}{127}{}{theorem.8.2}{}}
\newlabel{p1c8:def:better_formulations}{{8.3}{128}{}{theorem.8.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.4}Exercises}{129}{section.8.4}\protected@file@percent }
\newlabel{eq:31}{{8.7}{131}{Exercise 8.4: TSP formulation - tightening the MTZ formulation}{equation.8.4.7}{}}
\newlabel{eq:32}{{8.8}{131}{Exercise 8.4: TSP formulation - tightening the MTZ formulation}{equation.8.4.8}{}}
\newlabel{eq:34}{{8.10}{131}{Exercise 8.4: TSP formulation - tightening the MTZ formulation}{equation.8.4.10}{}}
\newlabel{p1c1:eq:constM1}{{8.11}{132}{Exercise 8.6: Piecewise linear objective functions and logical constraints}{equation.8.4.11}{}}
\newlabel{p1c1:eq:constM2}{{8.12}{132}{Exercise 8.6: Piecewise linear objective functions and logical constraints}{equation.8.4.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.9}{\ignorespaces The feasible region of the problem, and the contours of the objective function}}{133}{figure.caption.101}\protected@file@percent }
\newlabel{p1c8:fig:E86-plot}{{8.9}{133}{The feasible region of the problem, and the contours of the objective function}{figure.caption.101}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Branch-and-bound Method}{135}{chapter.9}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter_9}{{9}{135}{Branch-and-bound Method}{chapter.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.1}Optimality for integer programming problems}{135}{section.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9.2}Relaxations}{135}{section.9.2}\protected@file@percent }
\newlabel{p1c9:def:relaxation}{{9.1}{136}{Relaxation}{theorem.9.1}{}}
\newlabel{p1c9:prop:relaxation_bounding}{{9.2}{136}{}{theorem.9.2}{}}
\newlabel{p1c9:prop:relaxation_optimality}{{9.3}{137}{}{theorem.9.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.1}Linear programming relaxation}{137}{subsection.9.2.1}\protected@file@percent }
\newlabel{p1c9:prop:tighter_relaxations}{{9.5}{137}{}{theorem.9.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.1}{\ignorespaces The feasible region of the example (represented by the blue dots) and the solution of the LP relaxation, with objective function value $z_{LP} = 8.42$}}{138}{figure.caption.102}\protected@file@percent }
\newlabel{p1c9:fig:LP_relaxation}{{9.1}{138}{The feasible region of the example (represented by the blue dots) and the solution of the LP relaxation, with objective function value $z_{LP} = 8.42$}{figure.caption.102}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.2}Relaxation for combinatorial optimisation}{138}{subsection.9.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9.2}{\ignorespaces An example of a 1-tree considering eight nodes}}{139}{figure.caption.103}\protected@file@percent }
\newlabel{p1c9:fig:1-tree}{{9.2}{139}{An example of a 1-tree considering eight nodes}{figure.caption.103}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.3}Branch-and-bound method}{139}{section.9.3}\protected@file@percent }
\newlabel{p1c9:prop:divide-and-conquer}{{9.6}{139}{}{theorem.9.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.3}{\ignorespaces A enumeration tree using binary branching for a problem with three binary variables}}{140}{figure.caption.104}\protected@file@percent }
\newlabel{p1c9:fig:binary_tree}{{9.3}{140}{A enumeration tree using binary branching for a problem with three binary variables}{figure.caption.104}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3.1}Bounding in enumerative trees}{140}{subsection.9.3.1}\protected@file@percent }
\newlabel{section_913}{{9.3.1}{140}{Bounding in enumerative trees}{subsection.9.3.1}{}}
\newlabel{p1c9:prop:bounding}{{9.7}{140}{}{theorem.9.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3.2}Linear-programming-based branch-and-bound}{141}{subsection.9.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9.4}{\ignorespaces An example of pruning by optimality. Since the solution of LP relaxation of subproblem $S_1$ is integer, $x = (2,2)$ must be optimal for $S_1$}}{142}{figure.caption.105}\protected@file@percent }
\newlabel{p1c9:fig:prune_by_optimality}{{9.4}{142}{An example of pruning by optimality. Since the solution of LP relaxation of subproblem $S_1$ is integer, $x = (2,2)$ must be optimal for $S_1$}{figure.caption.105}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.5}{\ignorespaces An example of pruning by bound. Notice that the newly found global bound holds for all subproblems. After solving the LP relaxation of $S_2$, we notice that $\overline  {z}_2 \le \underline  {z}$, which renders the pruning.}}{142}{figure.caption.106}\protected@file@percent }
\newlabel{p1c9:fig:pruning_by_bound}{{9.5}{142}{An example of pruning by bound. Notice that the newly found global bound holds for all subproblems. After solving the LP relaxation of $S_2$, we notice that $\overline {z}_2 \le \underline {z}$, which renders the pruning}{figure.caption.106}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5}{\ignorespaces LP-relaxation-based branch-and-bound}}{143}{algorithm.caption.107}\protected@file@percent }
\newlabel{p1c9:alg:BB}{{5}{143}{LP-relaxation-based branch-and-bound}{algorithm.caption.107}{}}
\newlabel{p1c9:alg:BB_loop}{{2}{143}{LP-relaxation-based branch-and-bound}{algorithm.caption.107}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.6}{\ignorespaces LP relaxation of the problem $S$}}{143}{figure.caption.108}\protected@file@percent }
\newlabel{p1c9:fig:example_LP_relaxation_solution}{{9.6}{143}{LP relaxation of the problem $S$}{figure.caption.108}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.7}{\ignorespaces The branch-and-bound tree after branching $S$ onto $S_1$ and $S_2$}}{144}{figure.caption.109}\protected@file@percent }
\newlabel{p1c9:fig:example_bb_tree_1}{{9.7}{144}{The branch-and-bound tree after branching $S$ onto $S_1$ and $S_2$}{figure.caption.109}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.8}{\ignorespaces LP relaxation of subproblem $S_1$}}{144}{figure.caption.110}\protected@file@percent }
\newlabel{p1c9:fig:example_LP_relaxation_solution_2}{{9.8}{144}{LP relaxation of subproblem $S_1$}{figure.caption.110}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.9}{\ignorespaces The branch-and-bound tree after branching $S_1$ onto $S_{11}$ and $S_{12}$}}{145}{figure.caption.111}\protected@file@percent }
\newlabel{p1c9:fig:example_bb_tree_2}{{9.9}{145}{The branch-and-bound tree after branching $S_1$ onto $S_{11}$ and $S_{12}$}{figure.caption.111}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.10}{\ignorespaces LP relaxations of all subproblems. Notice that $S_{11}$ and $S_{12}$ includes the constraints $x_1 \le 2$ from the parent node $S_1$}}{145}{figure.caption.112}\protected@file@percent }
\newlabel{p1c9:fig:example_LP_relaxation_solution_3}{{9.10}{145}{LP relaxations of all subproblems. Notice that $S_{11}$ and $S_{12}$ includes the constraints $x_1 \le 2$ from the parent node $S_1$}{figure.caption.112}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.11}{\ignorespaces The final branch-and-bound tree}}{145}{figure.caption.113}\protected@file@percent }
\newlabel{p1c9:fig:example_bb_tree_3}{{9.11}{145}{The final branch-and-bound tree}{figure.caption.113}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.4}Exercises}{146}{section.9.4}\protected@file@percent }
\newlabel{IP:1}{{9.1}{146}{Problem 9.1: Uncapacitated Facility Location (UFL)}{equation.9.4.1}{}}
\newlabel{IP:2}{{9.2}{146}{Problem 9.1: Uncapacitated Facility Location (UFL)}{equation.9.4.2}{}}
\newlabel{IP:3}{{9.3}{146}{Problem 9.1: Uncapacitated Facility Location (UFL)}{equation.9.4.3}{}}
\newlabel{IP:4}{{9.4}{146}{Problem 9.1: Uncapacitated Facility Location (UFL)}{equation.9.4.4}{}}
\newlabel{IP:5}{{9.5}{146}{Problem 9.1: Uncapacitated Facility Location (UFL)}{equation.9.4.5}{}}
\newlabel{SIP:1}{{9.6}{146}{Problem 9.1: Uncapacitated Facility Location (UFL)}{equation.9.4.6}{}}
\newlabel{SIP:2}{{9.7}{146}{Problem 9.1: Uncapacitated Facility Location (UFL)}{equation.9.4.7}{}}
\newlabel{SIP:3}{{9.8}{146}{Problem 9.1: Uncapacitated Facility Location (UFL)}{equation.9.4.8}{}}
\newlabel{SIP:4}{{9.9}{146}{Problem 9.1: Uncapacitated Facility Location (UFL)}{equation.9.4.9}{}}
\newlabel{SIP:5}{{9.10}{146}{Problem 9.1: Uncapacitated Facility Location (UFL)}{equation.9.4.10}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {10}Cutting-planes Method}{149}{chapter.10}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter_10}{{10}{149}{Cutting-planes Method}{chapter.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.1}Valid inequalities}{149}{section.10.1}\protected@file@percent }
\newlabel{p1c10:def:valid_inequality}{{10.1}{149}{Valid inequality}{theorem.10.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.1}{\ignorespaces Illustration of a valid inequality being added to a formulation $P$. Notice how the inequality cuts off a portion of the polyhedral set $P$ while not removing any of the feasible points $X$ (represented by the dots)}}{150}{figure.caption.118}\protected@file@percent }
\newlabel{p1c10:fig:valid_inequality}{{10.1}{150}{Illustration of a valid inequality being added to a formulation $P$. Notice how the inequality cuts off a portion of the polyhedral set $P$ while not removing any of the feasible points $X$ (represented by the dots)}{figure.caption.118}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.2}The Chv\'atal-Gomory procedure}{150}{section.10.2}\protected@file@percent }
\newlabel{p1c10:prop:valid_inequality_LP}{{10.2}{150}{Valid inequalities for polyhedral sets}{theorem.10.2}{}}
\newlabel{p1c10:prop:valid_inequality_IP}{{10.3}{151}{Valid inequalities for integer sets}{theorem.10.3}{}}
\newlabel{p1c10:def:CG-procedure}{{10.4}{151}{Chv\'atal-Gomory procedure}{theorem.10.4}{}}
\newlabel{p1c10:thm:VG_valid_inequality}{{10.5}{152}{}{theorem.10.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.3}The cutting-plane method}{152}{section.10.3}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {6}{\ignorespaces Cutting-plane algorithm}}{152}{algorithm.caption.119}\protected@file@percent }
\newlabel{p1c10:alg:cuting-plane}{{6}{152}{Cutting-plane algorithm}{algorithm.caption.119}{}}
\newlabel{Alg2:loop}{{2}{152}{Cutting-plane algorithm}{algorithm.caption.119}{}}
\newlabel{Alg2:SepProb}{{4}{152}{Cutting-plane algorithm}{algorithm.caption.119}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.4}Gomory's fractional cutting-plane method}{153}{section.10.4}\protected@file@percent }
\newlabel{p1c10:eq:CG_cut}{{10.1}{153}{Gomory's fractional cutting-plane method}{equation.10.4.1}{}}
\newlabel{p1c10:eq:gomorycut}{{10.2}{154}{Gomory's fractional cutting-plane method}{equation.10.4.2}{}}
\newlabel{p1c10:prop:cuts_original}{{10.6}{155}{}{theorem.10.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.2}{\ignorespaces Feasible region of the LP relaxation (polyhedral set) and of the integer programming problem (blue dots) at each of three iterations taken to solve the integer programming problem. The inequalities in orange represent the Gomory cut added at each iteration}}{156}{figure.caption.120}\protected@file@percent }
\newlabel{p1c10:fig:LP_1}{{10.2}{156}{Feasible region of the LP relaxation (polyhedral set) and of the integer programming problem (blue dots) at each of three iterations taken to solve the integer programming problem. The inequalities in orange represent the Gomory cut added at each iteration}{figure.caption.120}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.5}Obtaining stronger inequalities}{156}{section.10.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.5.1}Strong inequalities}{156}{subsection.10.5.1}\protected@file@percent }
\newlabel{p1c10:def:dominance}{{10.7}{156}{Dominance}{theorem.10.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.3}{\ignorespaces Illustration of dominance between constraints. Notice that $x_1 + 3x_2 \le 4$ dominates $2x_1 + 4x_2 \le 9$ and is thus stronger}}{157}{figure.caption.121}\protected@file@percent }
\newlabel{p1c10:fig:dominance}{{10.3}{157}{Illustration of dominance between constraints. Notice that $x_1 + 3x_2 \le 4$ dominates $2x_1 + 4x_2 \le 9$ and is thus stronger}{figure.caption.121}{}}
\newlabel{p1c10:def:redundancy}{{10.8}{157}{Redundancy}{theorem.10.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.4}{\ignorespaces Illustration of a redundant inequality. Notice how the inequality $5x_1 - 2x_2 \le 6$ (in orange) does not dominate any of the other inequalities}}{157}{figure.caption.122}\protected@file@percent }
\newlabel{p1c10:fig:redundant}{{10.4}{157}{Illustration of a redundant inequality. Notice how the inequality $5x_1 - 2x_2 \le 6$ (in orange) does not dominate any of the other inequalities}{figure.caption.122}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.5.2}Strengthening 0-1 knapsack inequalities}{158}{subsection.10.5.2}\protected@file@percent }
\newlabel{p1c10:def:minimal_cover}{{10.9}{158}{minimal cover}{theorem.10.9}{}}
\newlabel{p1c10:prop:cover_inequalities}{{10.10}{158}{}{theorem.10.10}{}}
\newlabel{p1c10:prop:extended_cover}{{10.11}{159}{}{theorem.10.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.6}Exercises}{160}{section.10.6}\protected@file@percent }
\newlabel{eq:M}{{10.3}{160}{Exercise 10.1: Chv\'atal-Gomory (C-G) procedure}{equation.10.6.3}{}}
\newlabel{eq:tau}{{10.4}{160}{Exercise 10.1: Chv\'atal-Gomory (C-G) procedure}{equation.10.6.4}{}}
\newlabel{eq:41}{{10.5}{160}{Exercise 10.1: Chv\'atal-Gomory (C-G) procedure}{equation.10.6.5}{}}
\newlabel{eq:42}{{10.6}{160}{Exercise 10.1: Chv\'atal-Gomory (C-G) procedure}{equation.10.6.6}{}}
\newlabel{eq:C4}{{10.7}{160}{Exercise 10.1: Chv\'atal-Gomory (C-G) procedure}{equation.10.6.7}{}}
\newlabel{eq:C51}{{10.8}{161}{Exercise 10.1: Chv\'atal-Gomory (C-G) procedure}{equation.10.6.8}{}}
\newlabel{eq:C52}{{10.9}{161}{Exercise 10.1: Chv\'atal-Gomory (C-G) procedure}{equation.10.6.9}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {11}Mixed-integer Programming Solvers}{163}{chapter.11}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter_11}{{11}{163}{Mixed-integer Programming Solvers}{chapter.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11.1}Modern mixed-integer linear programming solvers}{163}{section.11.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.1}{\ignorespaces The flowchart of a typical MIP solver. The nodes represent phases of the algorithm}}{164}{figure.caption.128}\protected@file@percent }
\newlabel{p1c11:fig:MIP_solver_flowchart}{{11.1}{164}{The flowchart of a typical MIP solver. The nodes represent phases of the algorithm}{figure.caption.128}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11.2}Presolving methods}{164}{section.11.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Detecting infeasibility and redundancy}{164}{section*.129}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Bound tightening}{165}{section*.130}\protected@file@percent }
\newlabel{p1c11:eq:upper_bound_ax}{{11.1}{165}{Bound tightening}{equation.11.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Coefficient tightening}{166}{section*.131}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Other methods}{166}{section*.132}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.3}Cut generation}{167}{section.11.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.3.1}Cut management: generation, selection and discarding}{168}{subsection.11.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.4}Variable selection: branching strategy}{168}{section.11.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Maximum infeasibility}{169}{section*.133}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Strong branching}{169}{section*.134}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Pseudo-cost branching}{170}{section*.135}\protected@file@percent }
\newlabel{p1c11:eq:fractionals}{{11.2}{170}{Pseudo-cost branching}{equation.11.4.2}{}}
\newlabel{p1c11:eq:improvement_estimates}{{11.3}{170}{Pseudo-cost branching}{equation.11.4.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{GUB branching}{170}{section*.136}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.5}Node selection}{171}{section.11.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Depth-first search (DFS) and breadth-first search (BFS)}{172}{section*.137}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Best bound}{172}{section*.138}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Best estimate or best projection}{172}{section*.139}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.6}Primal heuristics}{173}{section.11.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.6.1}Diving heuristics}{173}{subsection.11.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.6.2}Local searches and large-neighbourhood searches}{174}{subsection.11.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Relaxation-induced neighbourhood search (RINS) and Relaxation-enforced neighbourhood search}{174}{section*.140}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Local branching}{175}{section*.141}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Feasibility pump}{175}{section*.142}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.7}Exercises}{177}{section.11.7}\protected@file@percent }
\newlabel{IP:1}{{11.4}{177}{Problem 11.1: Preprocessing and primal heuristics}{equation.11.7.4}{}}
\newlabel{IP:2}{{11.5}{177}{Problem 11.1: Preprocessing and primal heuristics}{equation.11.7.5}{}}
\newlabel{IP:3}{{11.6}{177}{Problem 11.1: Preprocessing and primal heuristics}{equation.11.7.6}{}}
\newlabel{IP:4}{{11.7}{177}{Problem 11.1: Preprocessing and primal heuristics}{equation.11.7.7}{}}
\newlabel{IP:5}{{11.8}{177}{Problem 11.1: Preprocessing and primal heuristics}{equation.11.7.8}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {12}Decomposition Methods}{179}{chapter.12}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter_12}{{12}{179}{Decomposition Methods}{chapter.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.1}Large-scale problems}{179}{section.12.1}\protected@file@percent }
\newlabel{section_71}{{12.1}{179}{Large-scale problems}{section.12.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.2}Dantzig-Wolfe decomposition and column generation*}{181}{section.12.2}\protected@file@percent }
\newlabel{section_72}{{12.2}{181}{Dantzig-Wolfe decomposition and column generation*}{section.12.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.2.1}Resolution theorem}{181}{subsection.12.2.1}\protected@file@percent }
\newlabel{p1c7:thm:resolution_theorem}{{12.1}{181}{Resolution theorem}{theorem.12.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.1}{\ignorespaces Example showing that every point of $P = \left \{ x_1 - x_2 \geq -2; x_1 + x_2 \geq 1, x_1,x_2 \geq 0 \right \}$ can be represented as a convex combination of its extreme point and a linear combination of its extreme rays}}{182}{figure.caption.145}\protected@file@percent }
\newlabel{p1c7:fig:resolution_example}{{12.1}{182}{Example showing that every point of $P = \braces {x_1 - x_2 \geq -2; x_1 + x_2 \geq 1, x_1,x_2 \geq 0}$ can be represented as a convex combination of its extreme point and a linear combination of its extreme rays}{figure.caption.145}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.2.2}Dantzig-Wolfe decomposition}{182}{subsection.12.2.2}\protected@file@percent }
\newlabel{p1c7:eq:resolution_representation}{{12.1}{183}{Dantzig-Wolfe decomposition}{equation.12.2.1}{}}
\newlabel{p1c7:eq:pm_const}{{12.2}{183}{Dantzig-Wolfe decomposition}{equation.12.2.2}{}}
\newlabel{p1c7:eq:cc_const}{{12.3}{183}{Dantzig-Wolfe decomposition}{equation.12.2.3}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {7}{\ignorespaces Dantzig-Wolfe decomposition}}{185}{algorithm.caption.146}\protected@file@percent }
\newlabel{p1c7:alg:DW}{{7}{185}{Dantzig-Wolfe decomposition}{algorithm.caption.146}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.2.3}Delayed column generation}{185}{subsection.12.2.3}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {8}{\ignorespaces Column generation algorithm}}{186}{algorithm.caption.147}\protected@file@percent }
\newlabel{p1c7:alg:CG}{{8}{186}{Column generation algorithm}{algorithm.caption.147}{}}
\newlabel{Alg2:loop}{{2}{186}{Column generation algorithm}{algorithm.caption.147}{}}
\newlabel{p1c7:alg:CGcolgen}{{6}{186}{Column generation algorithm}{algorithm.caption.147}{}}
\newlabel{p1c7:thm:CG_bound}{{12.2}{186}{}{theorem.12.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.3}Benders decomposition}{187}{section.12.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.3.1}Parametric optimisation problems}{187}{subsection.12.3.1}\protected@file@percent }
\newlabel{section_731}{{12.3.1}{187}{Parametric optimisation problems}{subsection.12.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.3.2}Properties of the optimal value function $F(b)$}{188}{subsection.12.3.2}\protected@file@percent }
\newlabel{section_732}{{12.3.2}{188}{Properties of the optimal value function $F(b)$}{subsection.12.3.2}{}}
\newlabel{p1c7:eq:function_F}{{12.7}{188}{Properties of the optimal value function $F(b)$}{equation.12.3.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.2}{\ignorespaces The optimal cost function $F$ as a function of $b$ in the direction $d$. The feasibility set $S_D$ has three extreme points $p^1$, $p^2$, and $p_3$, each associated with a hyperplane $(p^i)^\top (\overline  {b} + \theta d)$}}{189}{figure.caption.148}\protected@file@percent }
\newlabel{p1c7:fig:b_function_theta}{{12.2}{189}{The optimal cost function $F$ as a function of $b$ in the direction $d$. The feasibility set $S_D$ has three extreme points $p^1$, $p^2$, and $p_3$, each associated with a hyperplane $(p^i)^\top (\overline {b} + \theta d)$}{figure.caption.148}{}}
\newlabel{p1c7:eq:subgradient_proof}{{12.9}{190}{Properties of the optimal value function $F(b)$}{equation.12.3.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.3}{\ignorespaces The subgradients of the function $F$ at $\overline  {b}$. On the left, the unique subgradient of $F$ at $\overline  {b}$ is the gradient of the affine function $F(\overline  {b}) + p^\top (b - \overline  {b})$. On the right, the gradient of the affine function $F(\overline  {b}) + p^\top (b - \overline  {b})$ at $\overline  {b}$ is contained in a subgradient for $F$ at $\overline  {b}$.}}{190}{figure.caption.149}\protected@file@percent }
\newlabel{p1c7:fig:b_function}{{12.3}{190}{The subgradients of the function $F$ at $\overline {b}$. On the left, the unique subgradient of $F$ at $\overline {b}$ is the gradient of the affine function $F(\overline {b}) + p^\top (b - \overline {b})$. On the right, the gradient of the affine function $F(\overline {b}) + p^\top (b - \overline {b})$ at $\overline {b}$ is contained in a subgradient for $F$ at $\overline {b}$}{figure.caption.149}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.3.3}Benders decomposition}{190}{subsection.12.3.3}\protected@file@percent }
\newlabel{p1c7:eq:feas_cut_all}{{12.11}{192}{Benders decomposition}{equation.12.3.11}{}}
\newlabel{p1c7:eq:optimal_value_function_z}{{12.12}{192}{Benders decomposition}{equation.12.3.12}{}}
\newlabel{p1c7:eq:opt_cut_all1}{{12.13}{192}{Benders decomposition}{equation.12.3.13}{}}
\newlabel{p1c7:eq:opt_cut_all2}{{12.14}{192}{Benders decomposition}{equation.12.3.14}{}}
\newlabel{p1c7:eq:opt_cut}{{12.15}{192}{Benders decomposition}{equation.12.3.15}{}}
\newlabel{p1c7:eq:feas_cut}{{12.16}{192}{Benders decomposition}{equation.12.3.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.4}{\ignorespaces $z_k(x)$ is described by 3 line segments. At iteration $l=3$, two are available. The solution to $P_M^3$ returns $\overline  {\theta }^3$, which is lower than $z(\overline  {x}^3)$, obtained solving $S_k^D$ for $\overline  {x}^l$. The solution $p^*_k = p^3_k$ from $z(\overline  {x}^l)$ defines the missing segment $(p^*_k)^\top (e_k - C_kx)$. A new optimality cut is added and in iteration $l=4$, $\overline  {x}^4$ is obtained from solving $P_M^4$. Notice that we would have $\overline  {\theta }^{4} = z(\overline  {x}^{4})$, meaning that the algorithm terminates.}}{194}{figure.caption.150}\protected@file@percent }
\newlabel{p1c7:fig:benders_iteration}{{12.4}{194}{$z_k(x)$ is described by 3 line segments. At iteration $l=3$, two are available. The solution to $P_M^3$ returns $\overline {\theta }^3$, which is lower than $z(\overline {x}^3)$, obtained solving $S_k^D$ for $\overline {x}^l$. The solution $p^*_k = p^3_k$ from $z(\overline {x}^l)$ defines the missing segment $(p^*_k)^\top (e_k - C_kx)$. A new optimality cut is added and in iteration $l=4$, $\overline {x}^4$ is obtained from solving $P_M^4$. Notice that we would have $\overline {\theta }^{4} = z(\overline {x}^{4})$, meaning that the algorithm terminates}{figure.caption.150}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {9}{\ignorespaces Benders decomposition}}{194}{algorithm.caption.151}\protected@file@percent }
\newlabel{p1c7:alg:benders}{{9}{194}{Benders decomposition}{algorithm.caption.151}{}}
\newlabel{p1c7:alg:benders-loop}{{4}{194}{Benders decomposition}{algorithm.caption.151}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.4}Exercises}{196}{section.12.4}\protected@file@percent }
\bibstyle{plain}
\bibdata{optimization-notes-bib}
\gdef \@abspage@last{199}
